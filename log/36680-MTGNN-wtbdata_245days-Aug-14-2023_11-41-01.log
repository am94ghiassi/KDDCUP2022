2023-08-14 11:41:01,947 - INFO - Log directory: ./log
2023-08-14 11:41:01,947 - INFO - {'data_path': '/datadrive/data/grow/', 'filename': 'wtbdata_245days.csv', 'input_len': 144, 'output_len': 288, 'var_len': 5, 'capacity': 134, 'patient': 5, 'train_days': 214, 'val_days': 31, 'test_days': 0, 'total_days': 245, 'seed': 0, 'best': 3, 'num_workers': 2, 'epoch': 30, 'batch_size': 32, 'output_path': './output/', 'log_per_steps': 100, 'lr': 0.001, 'clip_norm': 5, 'weight_decay': 0, 'learner': 'adam', 'lr_decay': False, 'lr_scheduler_type': 'None', 'lr_eta_min': 1e-05, 'lr_decay_ratio': 0.1, 'lr_warmup_epoch': 5, 'lr_warmup_init': 1e-06, 'loss': 'FilterHuberLoss', 'conf': './config.yaml', 'model': 'MTGNN', 'gpu_id': 0, 'random': False, 'enhance': True, 'only_useful': True, 'data_diff': False, 'add_apt': False, 'binary': True, 'graph_type': 'geo', 'dtw_topk': 5, 'weight_adj_epsilon': 0.8, 'gsteps': 1, 'select': ['weekday', 'time', 'Wspd', 'Etmp', 'Itmp', 'Prtv', 'Patv'], 'exp_id': '36680'}
2023-08-14 11:41:12,032 - INFO - adding time
2023-08-14 11:41:16,163 - INFO - geo graph links: 1008.0
2023-08-14 11:41:16,165 - INFO - data_shape: (134, 30816, 12)
2023-08-14 11:41:16,166 - INFO - graph: [[1. 1. 1. ... 0. 0. 0.]
 [1. 1. 1. ... 0. 0. 0.]
 [1. 1. 1. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 1. 1. 1.]
 [0. 0. 0. ... 1. 1. 1.]
 [0. 0. 0. ... 1. 1. 1.]]
2023-08-14 11:41:21,199 - INFO - adding time
2023-08-14 11:41:25,455 - INFO - geo graph links: 1008.0
2023-08-14 11:41:25,457 - INFO - data_shape: (134, 4608, 12)
2023-08-14 11:41:25,458 - INFO - graph: [[1. 1. 1. ... 0. 0. 0.]
 [1. 1. 1. ... 0. 0. 0.]
 [1. 1. 1. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 1. 1. 1.]
 [0. 0. 0. ... 1. 1. 1.]
 [0. 0. 0. ... 1. 1. 1.]]
2023-08-14 11:41:29,188 - INFO - receptive_field: 43
2023-08-14 11:41:29,196 - INFO - MTGNN(
  (filter_convs): ModuleList(
    (0): DilatedInception(
      (tconv): ModuleList(
        (0): Conv2d(32, 8, kernel_size=(1, 2), stride=(1, 1))
        (1): Conv2d(32, 8, kernel_size=(1, 3), stride=(1, 1))
        (2): Conv2d(32, 8, kernel_size=(1, 6), stride=(1, 1))
        (3): Conv2d(32, 8, kernel_size=(1, 7), stride=(1, 1))
      )
    )
    (1): DilatedInception(
      (tconv): ModuleList(
        (0): Conv2d(32, 8, kernel_size=(1, 2), stride=(1, 1), dilation=(1, 2))
        (1): Conv2d(32, 8, kernel_size=(1, 3), stride=(1, 1), dilation=(1, 2))
        (2): Conv2d(32, 8, kernel_size=(1, 6), stride=(1, 1), dilation=(1, 2))
        (3): Conv2d(32, 8, kernel_size=(1, 7), stride=(1, 1), dilation=(1, 2))
      )
    )
    (2): DilatedInception(
      (tconv): ModuleList(
        (0): Conv2d(32, 8, kernel_size=(1, 2), stride=(1, 1), dilation=(1, 4))
        (1): Conv2d(32, 8, kernel_size=(1, 3), stride=(1, 1), dilation=(1, 4))
        (2): Conv2d(32, 8, kernel_size=(1, 6), stride=(1, 1), dilation=(1, 4))
        (3): Conv2d(32, 8, kernel_size=(1, 7), stride=(1, 1), dilation=(1, 4))
      )
    )
  )
  (gate_convs): ModuleList(
    (0): DilatedInception(
      (tconv): ModuleList(
        (0): Conv2d(32, 8, kernel_size=(1, 2), stride=(1, 1))
        (1): Conv2d(32, 8, kernel_size=(1, 3), stride=(1, 1))
        (2): Conv2d(32, 8, kernel_size=(1, 6), stride=(1, 1))
        (3): Conv2d(32, 8, kernel_size=(1, 7), stride=(1, 1))
      )
    )
    (1): DilatedInception(
      (tconv): ModuleList(
        (0): Conv2d(32, 8, kernel_size=(1, 2), stride=(1, 1), dilation=(1, 2))
        (1): Conv2d(32, 8, kernel_size=(1, 3), stride=(1, 1), dilation=(1, 2))
        (2): Conv2d(32, 8, kernel_size=(1, 6), stride=(1, 1), dilation=(1, 2))
        (3): Conv2d(32, 8, kernel_size=(1, 7), stride=(1, 1), dilation=(1, 2))
      )
    )
    (2): DilatedInception(
      (tconv): ModuleList(
        (0): Conv2d(32, 8, kernel_size=(1, 2), stride=(1, 1), dilation=(1, 4))
        (1): Conv2d(32, 8, kernel_size=(1, 3), stride=(1, 1), dilation=(1, 4))
        (2): Conv2d(32, 8, kernel_size=(1, 6), stride=(1, 1), dilation=(1, 4))
        (3): Conv2d(32, 8, kernel_size=(1, 7), stride=(1, 1), dilation=(1, 4))
      )
    )
  )
  (residual_convs): ModuleList(
    (0-2): 3 x Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (skip_convs): ModuleList(
    (0): Conv2d(32, 64, kernel_size=(1, 138), stride=(1, 1))
    (1): Conv2d(32, 64, kernel_size=(1, 126), stride=(1, 1))
    (2): Conv2d(32, 64, kernel_size=(1, 102), stride=(1, 1))
  )
  (gconv1): ModuleList(
    (0-2): 3 x MixProp(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (gconv2): ModuleList(
    (0-2): 3 x MixProp(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (norm): ModuleList(
    (0): LayerNorm((32, 134, 138), eps=1e-05, elementwise_affine=True)
    (1): LayerNorm((32, 134, 126), eps=1e-05, elementwise_affine=True)
    (2): LayerNorm((32, 134, 102), eps=1e-05, elementwise_affine=True)
  )
  (start_conv): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1))
  (end_conv_1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
  (end_conv_2): Conv2d(128, 288, kernel_size=(1, 1), stride=(1, 1))
  (skip0): Conv2d(5, 64, kernel_size=(1, 144), stride=(1, 1))
  (skipE): Conv2d(32, 64, kernel_size=(1, 102), stride=(1, 1))
)
2023-08-14 11:41:29,198 - INFO - filter_convs.0.tconv.0.weight	torch.Size([8, 32, 1, 2])	cuda:0	True
2023-08-14 11:41:29,198 - INFO - filter_convs.0.tconv.0.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,198 - INFO - filter_convs.0.tconv.1.weight	torch.Size([8, 32, 1, 3])	cuda:0	True
2023-08-14 11:41:29,198 - INFO - filter_convs.0.tconv.1.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,198 - INFO - filter_convs.0.tconv.2.weight	torch.Size([8, 32, 1, 6])	cuda:0	True
2023-08-14 11:41:29,198 - INFO - filter_convs.0.tconv.2.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,198 - INFO - filter_convs.0.tconv.3.weight	torch.Size([8, 32, 1, 7])	cuda:0	True
2023-08-14 11:41:29,198 - INFO - filter_convs.0.tconv.3.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,198 - INFO - filter_convs.1.tconv.0.weight	torch.Size([8, 32, 1, 2])	cuda:0	True
2023-08-14 11:41:29,198 - INFO - filter_convs.1.tconv.0.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.1.tconv.1.weight	torch.Size([8, 32, 1, 3])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.1.tconv.1.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.1.tconv.2.weight	torch.Size([8, 32, 1, 6])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.1.tconv.2.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.1.tconv.3.weight	torch.Size([8, 32, 1, 7])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.1.tconv.3.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.2.tconv.0.weight	torch.Size([8, 32, 1, 2])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.2.tconv.0.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.2.tconv.1.weight	torch.Size([8, 32, 1, 3])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.2.tconv.1.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.2.tconv.2.weight	torch.Size([8, 32, 1, 6])	cuda:0	True
2023-08-14 11:41:29,199 - INFO - filter_convs.2.tconv.2.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - filter_convs.2.tconv.3.weight	torch.Size([8, 32, 1, 7])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - filter_convs.2.tconv.3.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.0.tconv.0.weight	torch.Size([8, 32, 1, 2])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.0.tconv.0.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.0.tconv.1.weight	torch.Size([8, 32, 1, 3])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.0.tconv.1.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.0.tconv.2.weight	torch.Size([8, 32, 1, 6])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.0.tconv.2.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.0.tconv.3.weight	torch.Size([8, 32, 1, 7])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.0.tconv.3.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.1.tconv.0.weight	torch.Size([8, 32, 1, 2])	cuda:0	True
2023-08-14 11:41:29,200 - INFO - gate_convs.1.tconv.0.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.1.tconv.1.weight	torch.Size([8, 32, 1, 3])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.1.tconv.1.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.1.tconv.2.weight	torch.Size([8, 32, 1, 6])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.1.tconv.2.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.1.tconv.3.weight	torch.Size([8, 32, 1, 7])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.1.tconv.3.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.2.tconv.0.weight	torch.Size([8, 32, 1, 2])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.2.tconv.0.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.2.tconv.1.weight	torch.Size([8, 32, 1, 3])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.2.tconv.1.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.2.tconv.2.weight	torch.Size([8, 32, 1, 6])	cuda:0	True
2023-08-14 11:41:29,201 - INFO - gate_convs.2.tconv.2.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - gate_convs.2.tconv.3.weight	torch.Size([8, 32, 1, 7])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - gate_convs.2.tconv.3.bias	torch.Size([8])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - residual_convs.0.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - residual_convs.0.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - residual_convs.1.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - residual_convs.1.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - residual_convs.2.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - residual_convs.2.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - skip_convs.0.weight	torch.Size([64, 32, 1, 138])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - skip_convs.0.bias	torch.Size([64])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - skip_convs.1.weight	torch.Size([64, 32, 1, 126])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - skip_convs.1.bias	torch.Size([64])	cuda:0	True
2023-08-14 11:41:29,202 - INFO - skip_convs.2.weight	torch.Size([64, 32, 1, 102])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - skip_convs.2.bias	torch.Size([64])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - gconv1.0.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - gconv1.0.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - gconv1.1.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - gconv1.1.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - gconv1.2.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - gconv1.2.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - gconv2.0.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - gconv2.0.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,203 - INFO - gconv2.1.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - gconv2.1.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - gconv2.2.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - gconv2.2.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - norm.0.weight	torch.Size([32, 134, 138])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - norm.0.bias	torch.Size([32, 134, 138])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - norm.1.weight	torch.Size([32, 134, 126])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - norm.1.bias	torch.Size([32, 134, 126])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - norm.2.weight	torch.Size([32, 134, 102])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - norm.2.bias	torch.Size([32, 134, 102])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - start_conv.weight	torch.Size([32, 5, 1, 1])	cuda:0	True
2023-08-14 11:41:29,204 - INFO - start_conv.bias	torch.Size([32])	cuda:0	True
2023-08-14 11:41:29,205 - INFO - end_conv_1.weight	torch.Size([128, 64, 1, 1])	cuda:0	True
2023-08-14 11:41:29,205 - INFO - end_conv_1.bias	torch.Size([128])	cuda:0	True
2023-08-14 11:41:29,205 - INFO - end_conv_2.weight	torch.Size([288, 128, 1, 1])	cuda:0	True
2023-08-14 11:41:29,205 - INFO - end_conv_2.bias	torch.Size([288])	cuda:0	True
2023-08-14 11:41:29,205 - INFO - skip0.weight	torch.Size([64, 5, 1, 144])	cuda:0	True
2023-08-14 11:41:29,205 - INFO - skip0.bias	torch.Size([64])	cuda:0	True
2023-08-14 11:41:29,205 - INFO - skipE.weight	torch.Size([64, 32, 1, 102])	cuda:0	True
2023-08-14 11:41:29,205 - INFO - skipE.bias	torch.Size([64])	cuda:0	True
2023-08-14 11:41:29,205 - INFO - Total parameter numbers: 4238976
2023-08-14 11:41:29,206 - INFO - You select `adam` optimizer.
2023-08-14 11:42:27,000 - INFO - Step 100 Train Loss: 0.265624463558197
2023-08-14 11:43:23,444 - INFO - Step 200 Train Loss: 0.2549475133419037
2023-08-14 11:44:19,613 - INFO - Step 300 Train Loss: 0.41083207726478577
2023-08-14 11:45:15,789 - INFO - Step 400 Train Loss: 0.27293747663497925
2023-08-14 11:46:12,185 - INFO - Step 500 Train Loss: 0.32410943508148193
2023-08-14 11:47:08,325 - INFO - Step 600 Train Loss: 0.2922284007072449
2023-08-14 11:48:04,998 - INFO - Step 700 Train Loss: 0.31062278151512146
2023-08-14 11:49:01,231 - INFO - Step 800 Train Loss: 0.3050827085971832
2023-08-14 11:49:57,343 - INFO - Step 900 Train Loss: 0.2446759194135666
2023-08-14 11:50:24,586 - INFO - Epoch=0, exp_id=36680, Train Loss: 0.3066656566740213
2023-08-14 11:52:06,254 - INFO - Epoch=0, exp_id=36680, Valid {'mae': 37.07171054247357, 'score': 40.371474464809125, 'rmse': 43.671238387144676, 'farm_mae': 41.191616, 'farm_score': 44.383514404296875, 'farm_rmse': 47.57541, 'loss': 0.23724549816821822}
2023-08-14 11:52:33,757 - INFO - Step 1000 Train Loss: 0.27538809180259705
2023-08-14 11:53:26,871 - INFO - Step 1100 Train Loss: 0.37734276056289673
2023-08-14 11:54:19,931 - INFO - Step 1200 Train Loss: 0.3024477958679199
2023-08-14 11:55:13,123 - INFO - Step 1300 Train Loss: 0.23522862792015076
2023-08-14 11:56:06,275 - INFO - Step 1400 Train Loss: 0.29158034920692444
2023-08-14 11:56:59,698 - INFO - Step 1500 Train Loss: 0.2922239303588867
2023-08-14 11:57:53,027 - INFO - Step 1600 Train Loss: 0.22304050624370575
2023-08-14 11:58:46,184 - INFO - Step 1700 Train Loss: 0.34819069504737854
2023-08-14 11:59:39,429 - INFO - Step 1800 Train Loss: 0.23512336611747742
2023-08-14 12:00:33,121 - INFO - Epoch=1, exp_id=36680, Train Loss: 0.29601600968737246
2023-08-14 12:02:15,823 - INFO - Epoch=1, exp_id=36680, Valid {'mae': 35.28810809452247, 'score': 38.80462634773613, 'rmse': 42.321144600949786, 'farm_mae': 38.86496, 'farm_score': 42.65930938720703, 'farm_rmse': 46.453663, 'loss': 0.24132199680702832}
2023-08-14 12:02:17,410 - INFO - Step 1900 Train Loss: 0.36942464113235474
2023-08-14 12:03:13,044 - INFO - Step 2000 Train Loss: 0.30159586668014526
2023-08-14 12:04:08,703 - INFO - Step 2100 Train Loss: 0.28054556250572205
2023-08-14 12:05:04,486 - INFO - Step 2200 Train Loss: 0.2729644477367401
2023-08-14 12:06:00,367 - INFO - Step 2300 Train Loss: 0.3594726622104645
2023-08-14 12:06:56,388 - INFO - Step 2400 Train Loss: 0.2450074702501297
2023-08-14 12:07:53,070 - INFO - Step 2500 Train Loss: 0.22152796387672424
2023-08-14 12:08:49,038 - INFO - Step 2600 Train Loss: 0.300430029630661
2023-08-14 12:09:45,086 - INFO - Step 2700 Train Loss: 0.2636343240737915
2023-08-14 12:10:40,941 - INFO - Step 2800 Train Loss: 0.281696081161499
2023-08-14 12:11:07,248 - INFO - Epoch=2, exp_id=36680, Train Loss: 0.2789944979049132
2023-08-14 12:12:50,871 - INFO - Epoch=2, exp_id=36680, Valid {'mae': 35.66342690227357, 'score': 39.315795500843805, 'rmse': 42.96816409941404, 'farm_mae': 38.741837, 'farm_score': 42.90209197998047, 'farm_rmse': 47.062344, 'loss': 0.26319495373839186}
2023-08-14 12:13:20,887 - INFO - Step 2900 Train Loss: 0.28259438276290894
2023-08-14 12:14:16,690 - INFO - Step 3000 Train Loss: 0.2221556007862091
2023-08-14 12:15:12,567 - INFO - Step 3100 Train Loss: 0.25085362792015076
2023-08-14 12:16:08,501 - INFO - Step 3200 Train Loss: 0.231557235121727
2023-08-14 12:17:04,507 - INFO - Step 3300 Train Loss: 0.28003156185150146
2023-08-14 12:18:00,724 - INFO - Step 3400 Train Loss: 0.20719128847122192
2023-08-14 12:18:56,695 - INFO - Step 3500 Train Loss: 0.27928605675697327
2023-08-14 12:19:52,634 - INFO - Step 3600 Train Loss: 0.24841928482055664
2023-08-14 12:20:48,622 - INFO - Step 3700 Train Loss: 0.23174259066581726
2023-08-14 12:21:42,442 - INFO - Epoch=3, exp_id=36680, Train Loss: 0.2571116505922834
2023-08-14 12:23:25,780 - INFO - Epoch=3, exp_id=36680, Valid {'mae': 34.953079844912594, 'score': 38.867887938209186, 'rmse': 42.78269603150578, 'farm_mae': 37.44711, 'farm_score': 42.22679138183594, 'farm_rmse': 47.00647, 'loss': 0.2635343352489117}
2023-08-14 12:23:28,439 - INFO - Step 3800 Train Loss: 0.3016257584095001
2023-08-14 12:24:24,162 - INFO - Step 3900 Train Loss: 0.22400783002376556
2023-08-14 12:25:19,912 - INFO - Step 4000 Train Loss: 0.23967882990837097
2023-08-14 12:26:16,146 - INFO - Step 4100 Train Loss: 0.24154162406921387
2023-08-14 12:27:10,663 - INFO - Step 4200 Train Loss: 0.26855987310409546
2023-08-14 12:28:04,146 - INFO - Step 4300 Train Loss: 0.23594820499420166
2023-08-14 12:28:57,513 - INFO - Step 4400 Train Loss: 0.22659635543823242
2023-08-14 12:29:50,847 - INFO - Step 4500 Train Loss: 0.27166563272476196
2023-08-14 12:30:44,416 - INFO - Step 4600 Train Loss: 0.21173255145549774
2023-08-14 12:31:38,437 - INFO - Step 4700 Train Loss: 0.21711470186710358
2023-08-14 12:32:02,274 - INFO - Epoch=4, exp_id=36680, Train Loss: 0.22973060466592504
2023-08-14 12:33:44,639 - INFO - Epoch=4, exp_id=36680, Valid {'mae': 44.10602826173026, 'score': 47.660125345772954, 'rmse': 51.21422242981564, 'farm_mae': 49.130646, 'farm_score': 53.492889404296875, 'farm_rmse': 57.85513, 'loss': 0.3119780868576228}
2023-08-14 12:34:14,459 - INFO - Step 4800 Train Loss: 0.196921706199646
2023-08-14 12:35:07,788 - INFO - Step 4900 Train Loss: 0.22558137774467468
2023-08-14 12:36:01,597 - INFO - Step 5000 Train Loss: 0.20670820772647858
2023-08-14 12:36:55,014 - INFO - Step 5100 Train Loss: 0.24027866125106812
2023-08-14 12:37:48,434 - INFO - Step 5200 Train Loss: 0.2221720963716507
2023-08-14 12:38:42,311 - INFO - Step 5300 Train Loss: 0.21136438846588135
2023-08-14 12:39:35,832 - INFO - Step 5400 Train Loss: 0.22703483700752258
2023-08-14 12:40:29,469 - INFO - Step 5500 Train Loss: 0.18567094206809998
2023-08-14 12:41:23,158 - INFO - Step 5600 Train Loss: 0.20680466294288635
2023-08-14 12:42:13,378 - INFO - Epoch=5, exp_id=36680, Train Loss: 0.20980137396599896
2023-08-14 12:43:56,038 - INFO - Epoch=5, exp_id=36680, Valid {'mae': 40.77008837795249, 'score': 44.9679406198244, 'rmse': 49.1657928616963, 'farm_mae': 45.08274, 'farm_score': 50.26339340209961, 'farm_rmse': 55.444046, 'loss': 0.32020926641172354}
2023-08-14 12:43:59,638 - INFO - Step 5700 Train Loss: 0.15768268704414368
2023-08-14 12:44:53,024 - INFO - Step 5800 Train Loss: 0.18848666548728943
2023-08-14 12:45:46,340 - INFO - Step 5900 Train Loss: 0.2336903065443039
2023-08-14 12:46:39,777 - INFO - Step 6000 Train Loss: 0.17683689296245575
2023-08-14 12:47:33,107 - INFO - Step 6100 Train Loss: 0.19389863312244415
2023-08-14 12:48:26,533 - INFO - Step 6200 Train Loss: 0.16493500769138336
2023-08-14 12:49:20,093 - INFO - Step 6300 Train Loss: 0.18187998235225677
2023-08-14 12:50:13,587 - INFO - Step 6400 Train Loss: 0.2094852328300476
2023-08-14 12:51:07,152 - INFO - Step 6500 Train Loss: 0.17232884466648102
2023-08-14 12:52:00,730 - INFO - Step 6600 Train Loss: 0.14208176732063293
2023-08-14 12:52:23,539 - INFO - Epoch=6, exp_id=36680, Train Loss: 0.19484928884672037
2023-08-14 12:54:06,419 - INFO - Epoch=6, exp_id=36680, Valid {'mae': 39.1024379581262, 'score': 43.38229955034074, 'rmse': 47.66216114255528, 'farm_mae': 42.60206, 'farm_score': 47.86900329589844, 'farm_rmse': 53.135944, 'loss': 0.31453004008414975}
2023-08-14 12:54:37,236 - INFO - Step 6700 Train Loss: 0.16747397184371948
2023-08-14 12:55:30,879 - INFO - Step 6800 Train Loss: 0.1622886061668396
2023-08-14 12:56:24,523 - INFO - Step 6900 Train Loss: 0.21408596634864807
2023-08-14 12:57:18,017 - INFO - Step 7000 Train Loss: 0.16024306416511536
2023-08-14 12:58:11,509 - INFO - Step 7100 Train Loss: 0.20971496403217316
2023-08-14 12:59:04,981 - INFO - Step 7200 Train Loss: 0.16670167446136475
2023-08-14 12:59:58,904 - INFO - Step 7300 Train Loss: 0.19843144714832306
2023-08-14 13:00:54,968 - INFO - Step 7400 Train Loss: 0.19101090729236603
2023-08-14 13:01:51,248 - INFO - Step 7500 Train Loss: 0.21607021987438202
2023-08-14 13:02:43,057 - INFO - Epoch=7, exp_id=36680, Train Loss: 0.18292540672173366
2023-08-14 13:04:26,208 - INFO - Epoch=7, exp_id=36680, Valid {'mae': 38.46784068780902, 'score': 42.63426664598002, 'rmse': 46.800692604151024, 'farm_mae': 42.15206, 'farm_score': 47.01470947265625, 'farm_rmse': 51.877354, 'loss': 0.29483384148480785}
2023-08-14 13:04:26,209 - INFO - Best valid Epoch 1
2023-08-14 13:04:26,209 - INFO - Best valid score {'mae': 35.28810809452247, 'score': 38.80462634773613, 'rmse': 42.321144600949786, 'farm_mae': 38.86496, 'farm_score': 42.65930938720703, 'farm_rmse': 46.453663, 'loss': 0.24132199680702832}
